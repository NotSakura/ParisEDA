---
title: "Paris EDA"
author: "Sakura Noskor"
format: pdf
date: today
date-format: long
thanks: "Code and some data from this paper are available at: [github repo](https://github.com/NotSakura/ParisEDA.git)."
number-sections: true
bibliography: references.bib
---

# Data
Used Rstudio and R [@citeR] to create this with the help of arrow[@arr], lubricate [@lub], ggplot [@gg], tidyverse [@tidy], mice [@mice], modelsummary [@sum], and naniar [@nan]. 

```{r}
#| warning: false
#| echo: false
library(arrow)
library(janitor)
library(lubridate)
library(mice)
library(modelsummary)
library(naniar)
library(tidyverse)
```
# EDA

First we load the data from the site and save it

```{r}
#| warning: false
url <-
  paste0(
    "http://data.insideairbnb.com/france/ile-de-france/",
    "paris/2023-12-12/data/listings.csv.gz"
  )

airbnb_data <-
  read_csv(
    file = url,
    guess_max = 20000
  )

write_csv(airbnb_data, "airbnb_data.csv")

```



```{r}
#| warning: false
airbnb_data_selected <-
  airbnb_data |>
  select(
    host_id,
    host_response_time,
    host_is_superhost,
    host_total_listings_count,
    neighbourhood_cleansed,
    bathrooms,
    bedrooms,
    price,
    number_of_reviews,
    review_scores_rating,
    review_scores_accuracy,
    review_scores_value
  )

write_parquet(
  x = airbnb_data_selected, 
  sink = 
    "2023-12-12-paris-airbnblistings-select_variables.parquet"
  )

rm(airbnb_data)
```


Then we play with the data to see the values. Here we check the values for '$' and clean that up. 
```{r}
#| warning: false

airbnb_data_selected$price |>
  str_split("") |>
  unlist() |>
  unique()


airbnb_data_selected |>
  select(price) |>
  filter(str_detect(price, ","))


airbnb_data_selected <-
  airbnb_data_selected |>
  mutate(
    price = str_remove_all(price, "[\\$,]"),
    price = as.integer(price)
  )
```


Then we graph the distribution
```{r}
#| warning: false
airbnb_data_selected |>
  ggplot(aes(x = price)) +
  geom_histogram(binwidth = 10) +
  theme_classic() +
  labs(
    x = "Price per night",
    y = "Number of properties"
  )

airbnb_data_selected |>
  filter(price > 1000) |>
  ggplot(aes(x = price)) +
  geom_histogram(binwidth = 10) +
  theme_classic() +
  labs(
    x = "Price per night",
    y = "Number of properties"
  ) +
  scale_y_log10()
```


Then we filter the data to see how many properties have a nightly cost of less than \$1000 and also between \$90 and \$20

```{r}
#| warning: false
airbnb_data_selected |>
  filter(price < 1000) |>
  ggplot(aes(x = price)) +
  geom_histogram(binwidth = 10) +
  theme_classic() +
  labs(
    x = "Price per night",
    y = "Number of properties"
  )

airbnb_data_selected |>
  filter(price > 90) |>
  filter(price < 210) |>
  ggplot(aes(x = price)) +
  geom_histogram(binwidth = 1) +
  theme_classic() +
  labs(
    x = "Price per night",
    y = "Number of properties"
  )
```


Then we filter for the houses that are less than \$1000 and also filter them so there are no NA values in superhosts column and turn those values to binary (0 for false and 1 for true). Then we graph for visual representation. 
```{r}
#| warning: false
airbnb_data_less_1000 <-
  airbnb_data_selected |>
  filter(price < 1000)

airbnb_data_less_1000 |>
  filter(is.na(host_is_superhost))

airbnb_data_no_superhost_nas <-
  airbnb_data_less_1000 |>
  filter(!is.na(host_is_superhost)) |>
  mutate(
    host_is_superhost_binary =
      as.numeric(host_is_superhost)
  )

airbnb_data_no_superhost_nas |>
  ggplot(aes(x = review_scores_rating)) +
  geom_bar() +
  theme_classic() +
  labs(
    x = "Review scores rating",
    y = "Number of properties"
  )
```

Then we filter to see the how many places has a specific average review score. 
```{r}
#| warning: false
airbnb_data_no_superhost_nas |>
  filter(is.na(review_scores_rating)) |>
  nrow()

airbnb_data_no_superhost_nas |>
  filter(is.na(review_scores_rating)) |>
  select(number_of_reviews) |>
  table()


airbnb_data_no_superhost_nas |>
  filter(!is.na(review_scores_rating)) |>
  ggplot(aes(x = review_scores_rating)) +
  geom_histogram(binwidth = 1) +
  theme_classic() +
  labs(
    x = "Average review score",
    y = "Number of properties"
  )
```
We see that most number are high in this graph.

Then we look at response time for the houses that has reviews.
```{r}
#| warning: false
airbnb_data_has_reviews <-
  airbnb_data_no_superhost_nas |>
  filter(!is.na(review_scores_rating))


airbnb_data_has_reviews |>
  count(host_response_time)
```

```{r}
#| warning: false
airbnb_data_has_reviews <-
  airbnb_data_has_reviews |>
  mutate(
    host_response_time = if_else(
      host_response_time == "N/A",
      NA_character_,
      host_response_time
    ),
    host_response_time = factor(host_response_time)
  )

airbnb_data_has_reviews |>
  filter(is.na(host_response_time)) |>
  ggplot(aes(x = review_scores_rating)) +
  geom_histogram(binwidth = 1) +
  theme_classic() +
  labs(
    x = "Average review score",
    y = "Number of properties"
  )
```

Ggplot drops missing values but we want to include them so..

```{r}
#| warning: false
airbnb_data_has_reviews |>
  ggplot(aes(
    x = host_response_time,
    y = review_scores_accuracy
  )) +
  geom_miss_point() +
  labs(
    x = "Host response time",
    y = "Review score accuracy",
    color = "Is missing?"
  ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```


Remove people with NA as their response time
```{r}
#| warning: false
airbnb_data_selected <-
  airbnb_data_has_reviews |>
  filter(!is.na(host_response_time))
```


Now number of people that hosted an airbnb in paris
```{r}
#| warning: false
airbnb_data_selected |>
  ggplot(aes(x = host_total_listings_count)) +
  geom_histogram() +
  scale_x_log10() +
  labs(
    x = "Total number of listings, by host",
    y = "Number of hosts"
  )
```

The long tail is unusual. Now we clean the NA values

```{r}
#| warning: false
airbnb_data_selected |>
  filter(host_total_listings_count >= 500) |>
  head()
```


Nothing is weird so lets take a look at people with one property:
```{r}
#| warning: false
airbnb_data_selected <-
  airbnb_data_selected |>
  add_count(host_id) |>
  filter(n == 1) |>
  select(-n)
```




We want to look at the correlation between price and review so...
```{r}
#| warning: false
airbnb_data_selected |>
  filter(number_of_reviews > 1) |>
  ggplot(aes(x = price, y = review_scores_rating, 
             color = host_is_superhost)) +
  geom_point(size = 1, alpha = 0.1) +
  theme_classic() +
  labs(
    x = "Price per night",
    y = "Average review score",
    color = "Superhost"
  ) +
  scale_color_brewer(palette = "Set1")
```
Mostly shows that lower the price the more the average review is but lower ratings more probable in cheaper houses as compared to the high priced houses on airbnb.


Now we look at the superhost's response time:
```{r}
#| warning: false
airbnb_data_selected |>
  count(host_is_superhost) |>
  mutate(
    proportion = n / sum(n),
    proportion = round(proportion, digits = 2)
  )
```
but this table has NA values so lets look at hosts response time by whether they are a superhost or not.

```{r}
#| warning: false
airbnb_data_selected |>
  tabyl(host_response_time, host_is_superhost) |>
  adorn_percentages("col") |>
  adorn_pct_formatting(digits = 0) |>
  adorn_ns() |>
  adorn_title()
```


Then we look at the neighbourhood.
```{r}
#| warning: false
airbnb_data_selected |>
  tabyl(neighbourhood_cleansed) |>
  adorn_pct_formatting() |>
  arrange(-n) |>
  filter(n > 100) |>
  adorn_totals("row") |>
  head()
```

Then we estimate the model using `glm` and we use `modelsummary()` to see the values.
```{r}
#| warning: false
logistic_reg_superhost_response_review <-
  glm(
    host_is_superhost ~
      host_response_time +
      review_scores_rating,
    data = airbnb_data_selected,
    family = binomial
  )

modelsummary(logistic_reg_superhost_response_review)
```



Each row directly correlates to the likelihood of person being a superhost


```{r}
#| warning: false
#we save the data
write_parquet(
  x = airbnb_data_selected, 
  sink = "2023-05-05-paris-airbnblistings-analysis_dataset.parquet"
  )
```

